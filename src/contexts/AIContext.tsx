import { createContext, useContext, useState, useEffect, ReactNode } from 'react';
import { supabase } from '@/lib/supabase';

interface GeoLocationData {
  countryCode: string;
  detectedLanguage: string;
}

interface AIModelConfig {
  id: string;
  name: string;
  enabled: boolean;
  recommended: boolean;
  avgResponseTime?: number; // å¹³å‡å“åº”æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
  responseCount?: number; // å“åº”æ¬¡æ•°ï¼ˆç”¨äºè®¡ç®—å¹³å‡å“åº”æ—¶é—´ï¼‰
}

interface ModelConfigs {
  chat: {
    available: AIModelConfig[];
  };
  image: {
    available: AIModelConfig[];
  };
}

interface AIContextType {
  region: string;
  selectedChatModel: string;
  selectedImageModel: string;
  modelConfigs: ModelConfigs | null;
  isLoading: boolean;
  setSelectedChatModel: (model: string) => void;
  setSelectedImageModel: (model: string) => void;
  refreshGeoLocation: () => void;
  updateModelResponseTime: (modelId: string, responseTime: number) => void; // æ›´æ–°æ¨¡å‹å“åº”æ—¶é—´
  getModelResponseTime: (modelId: string) => number | undefined; // è·å–æ¨¡å‹å“åº”æ—¶é—´
  getPerformanceIndicator: (modelId: string) => string; // è·å–æ€§èƒ½æŒ‡æ ‡å›¾æ ‡
  getSortedModels: () => AIModelConfig[]; // è·å–æŒ‰å“åº”æ—¶é—´æ’åºçš„æ¨¡å‹åˆ—è¡¨
  getRecommendedModel: () => string; // è·å–æ¨èçš„æ¨¡å‹ï¼ˆæœ€å¿«çš„ï¼‰
  updateAverageResponseTime: (modelId: string, responseTime: number) => void; // æ›´æ–°æ¨¡å‹å¹³å‡å“åº”æ—¶é—´
}

const AIContext = createContext<AIContextType | undefined>(undefined);

interface AIProviderProps {
  children: ReactNode;
}

export function AIProvider({ children }: AIProviderProps) {
  const [region, setRegion] = useState('overseas');
  const [selectedChatModel, setSelectedChatModel] = useState('openai'); // é»˜è®¤ä½¿ç”¨OpenAI GPT-4o
  const [selectedImageModel, setSelectedImageModel] = useState('dall-e');
  const [modelConfigs, setModelConfigs] = useState<ModelConfigs | null>(null);
  const [isLoading, setIsLoading] = useState(true);

  const refreshGeoLocation = async () => {
    setIsLoading(true);
    try {
      // è°ƒç”¨æ¨¡å‹é€‰æ‹© Edge Function
      const { data, error } = await supabase.functions.invoke('geo-ai-model-selection', {
        method: 'GET',
      });

      if (error) {
        throw new Error(`æ¨¡å‹é€‰æ‹©æœåŠ¡é”™è¯¯: ${error.message}`);
      }

      console.log('è·å–åˆ°åœ°ç†å®šä½æ•°æ®:', data);
      const modelData = data.data;
      setRegion(modelData.region);

      // æ›´æ–°æ¨¡å‹é…ç½®
      setModelConfigs(modelData.modelConfigs);

      // è¯»å–å·²ä¿å­˜çš„ç”¨æˆ·é€‰æ‹©
      const savedChatModel = localStorage.getItem('leoai-chat-model');

      // æ¨èæ¨¡å‹ï¼ˆæœåŠ¡ç«¯åŸºäºåŒºåŸŸè¿”å›ï¼‰
      const recommendedChatModel = modelData.recommendedModels.chat;

      // å¦‚æœç”¨æˆ·æœªä¿å­˜è¿‡ï¼Œåˆ™é‡‡ç”¨æ¨è
      if (!savedChatModel) {
        setSelectedChatModel(recommendedChatModel);
        localStorage.setItem('leoai-chat-model', recommendedChatModel);
      } else {
        // è‹¥å·²ä¿å­˜è¿‡ï¼Œä½†è¯¥æ¨¡å‹åœ¨å½“å‰åŒºåŸŸä¸å¯ç”¨ï¼Œåˆ™åˆ‡åˆ°æ¨è
        const available = modelData.modelConfigs?.chat?.available || [];
        const savedAvailable = available.find(m => m.id === savedChatModel && m.enabled);
        const isChina = modelData.region === 'china' || modelData.region === 'CN';
        const isOverseas = !isChina;

        let nextModel = savedChatModel;
        if (!savedAvailable) {
          nextModel = recommendedChatModel;
        } else {
          // åŒºåŸŸä¼˜å…ˆç­–ç•¥ï¼šå›½å†…é¿å…ä¼˜å…ˆ OpenAIï¼›æµ·å¤–é¿å…ä¼˜å…ˆ Qwen
          if (isChina && savedChatModel === 'openai') nextModel = 'qwen';
          if (isOverseas && savedChatModel === 'qwen') nextModel = 'openai';
        }

        if (nextModel !== savedChatModel) {
          setSelectedChatModel(nextModel);
          localStorage.setItem('leoai-chat-model', nextModel);
        } else {
          setSelectedChatModel(savedChatModel);
        }
      }

      // å›¾ç‰‡æ¨¡å‹
      const savedImageModel = localStorage.getItem('leoai-image-model');
      if (!savedImageModel) {
        setSelectedImageModel(modelData.recommendedModels.image);
        localStorage.setItem('leoai-image-model', modelData.recommendedModels.image);
      }

      // ä¿å­˜åŒºåŸŸä¿¡æ¯
      localStorage.setItem('leoai-region', modelData.region);
      localStorage.setItem('leoai-recommended-model', recommendedChatModel);
    } catch (error) {
      console.error('è·å–åŸºäºåœ°ç†ä½ç½®çš„æ¨¡å‹é…ç½®å¤±è´¥:', error);
      // ä½¿ç”¨æœ¬åœ°å…œåº•é…ç½®
      setRegion('overseas');
      const defaultModel = 'openai';
      setSelectedChatModel(defaultModel);
      setSelectedImageModel('dall-e');
      setModelConfigs({
        chat: {
          available: [
            { id: 'openai', name: 'OpenAI GPT-4o', enabled: true, recommended: true },
            { id: 'qwen', name: 'Qwen Turbo', enabled: true, recommended: false },
            { id: 'deepseek', name: 'DeepSeek', enabled: true, recommended: false },
          ]
        },
        image: {
          available: [
            { id: 'dall-e', name: 'DALLÂ·E', enabled: true, recommended: true }
          ]
        }
      });
    } finally {
      setIsLoading(false);
    }
  };

  // è®¾ç½®åˆå§‹åŒ–çŠ¶æ€
  useEffect(() => {
    const initialize = async () => {
      try {
        setIsLoading(true);
        const savedChatModel = localStorage.getItem('leoai-chat-model');
        const savedImageModel = localStorage.getItem('leoai-image-model');
        const savedRegion = localStorage.getItem('leoai-region');
        const savedRecommendedModel = localStorage.getItem('leoai-recommended-model');

        if (savedChatModel) {
          setSelectedChatModel(savedChatModel);
        } else if (savedRecommendedModel) {
          setSelectedChatModel(savedRecommendedModel);
        } else {
          const currentLang = localStorage.getItem('i18nextLng') || 'en';
          const defaultModel = getRecommendedModelByUserPreference(currentLang);
          setSelectedChatModel(defaultModel);
          if (!modelConfigs) {
            setModelConfigs({
              chat: {
                available: [
                  { id: 'openai', name: 'OpenAI GPT-4o', enabled: true, recommended: true },
                  { id: 'qwen', name: 'Qwen Turbo', enabled: true, recommended: false },
                  { id: 'deepseek', name: 'DeepSeek', enabled: true, recommended: false },
                ]
              },
              image: {
                available: [
                  { id: 'dall-e', name: 'DALLÂ·E', enabled: true, recommended: true }
                ]
              }
            });
          }
        }
        if (savedImageModel) setSelectedImageModel(savedImageModel);
        if (savedRegion) setRegion(savedRegion);
        await refreshGeoLocation();
      } catch (error) {
        console.error('åˆå§‹åŒ–AIä¸Šä¸‹æ–‡å¤±è´¥:', error);
      } finally {
        setIsLoading(false);
      }
    };

    initialize();
  }, []);

  const handleSetSelectedChatModel = (model: string) => {
    console.log(`åˆ‡æ¢æ¨¡å‹ä¸º: ${model}`);
    setSelectedChatModel(model);
    localStorage.setItem('leoai-chat-model', model);
    window.dispatchEvent(new CustomEvent('model-changed', { detail: { model } }));
  };

  const handleSetSelectedImageModel = (model: string) => {
    setSelectedImageModel(model);
    localStorage.setItem('leoai-image-model', model);
  };

  const updateModelResponseTime = (modelId: string, responseTime: number) => {
    updateAverageResponseTime(modelId, responseTime);
  };

  const getModelResponseTime = (modelId: string): number | undefined => {
    if (!modelConfigs) return undefined;
    const model = modelConfigs.chat.available.find(m => m.id === modelId);
    if (model?.avgResponseTime) {
      return Math.round(model.avgResponseTime / 1000);
    }
    return undefined;
  };

  const getPerformanceIndicator = (modelId: string): string => {
    const responseTime = getModelResponseTime(modelId);
    if (responseTime === undefined) return 'âš™ï¸';
    if (responseTime <= 10) return 'âš¡';
    if (responseTime <= 20) return 'ğŸœ€';
    return 'ğŸš€';
  };
  
  const getSortedModels = (): AIModelConfig[] => {
    if (!modelConfigs) return [];
    const models = [...modelConfigs.chat.available];
    return models.sort((a, b) => {
      const timeA = a.avgResponseTime || Number.MAX_SAFE_INTEGER;
      const timeB = b.avgResponseTime || Number.MAX_SAFE_INTEGER;
      return timeA - timeB;
    });
  };
  
  const getRecommendedModelByUserPreference = (userLanguage: string): string => {
    const isChineseUser = userLanguage.toLowerCase().startsWith('zh');
    const timezone = new Date().getTimezoneOffset() / -60;
    const possibleChineseUser = isChineseUser || timezone === 8;
    if (possibleChineseUser && isChineseUser) {
      return 'qwen';
    } else {
      return 'openai';
    }
  };
  
  const getRecommendedModel = (): string => {
    const userDefinedModel = localStorage.getItem('leoai-chat-model-preference');
    if (userDefinedModel) return userDefinedModel;
    const currentLang = localStorage.getItem('i18nextLng') || 'en';
    const languageBasedModel = getRecommendedModelByUserPreference(currentLang);
    const sortedModels = getSortedModels();
    const fastestModel = sortedModels.find(m => m.enabled);
    const fastestModelId = fastestModel?.id || 'deepseek';
    return languageBasedModel || fastestModelId;
  };
  
  const updateAverageResponseTime = (modelId: string, responseTime: number) => {
    if (!modelConfigs) return;
    setModelConfigs((prevConfigs) => {
      if (!prevConfigs) return prevConfigs;
      const newConfigs = {
        ...prevConfigs,
        chat: {
          ...prevConfigs.chat,
          available: [...prevConfigs.chat.available]
        }
      };
      const idx = newConfigs.chat.available.findIndex(m => m.id === modelId);
      if (idx >= 0) {
        const m = { ...newConfigs.chat.available[idx] };
        // æŒ‡æ•°å¹³æ»‘æ›´æ–°
        const alpha = 0.3;
        const prev = m.avgResponseTime || responseTime;
        m.avgResponseTime = Math.round(alpha * responseTime + (1 - alpha) * prev);
        newConfigs.chat.available[idx] = m;
      }
      return newConfigs;
    });
  };

  return (
    <AIContext.Provider value={{
      region,
      selectedChatModel,
      selectedImageModel,
      modelConfigs,
      isLoading,
      setSelectedChatModel: handleSetSelectedChatModel,
      setSelectedImageModel: handleSetSelectedImageModel,
      refreshGeoLocation,
      updateModelResponseTime,
      getModelResponseTime,
      getPerformanceIndicator,
      getSortedModels,
      getRecommendedModel,
      updateAverageResponseTime,
    }}>
      {children}
    </AIContext.Provider>
  );
}

export function useAI() {
  const ctx = useContext(AIContext);
  if (!ctx) throw new Error('useAI must be used within AIProvider');
  return ctx;
}