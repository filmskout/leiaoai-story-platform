import { createContext, useContext, useState, useEffect, ReactNode } from 'react';
import { supabase } from '@/lib/supabase';

interface GeoLocationData {
  countryCode: string;
  detectedLanguage: string;
}

interface AIModelConfig {
  id: string;
  name: string;
  enabled: boolean;
  recommended: boolean;
  avgResponseTime?: number; // å¹³å‡å“åº”æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
  responseCount?: number; // å“åº”æ¬¡æ•°ï¼ˆç”¨äºè®¡ç®—å¹³å‡å“åº”æ—¶é—´ï¼‰
}

interface ModelConfigs {
  chat: {
    available: AIModelConfig[];
  };
  image: {
    available: AIModelConfig[];
  };
}

interface AIContextType {
  region: string;
  selectedChatModel: string;
  selectedImageModel: string;
  modelConfigs: ModelConfigs | null;
  isLoading: boolean;
  setSelectedChatModel: (model: string) => void;
  setSelectedImageModel: (model: string) => void;
  refreshGeoLocation: () => void;
  updateModelResponseTime: (modelId: string, responseTime: number) => void; // æ›´æ–°æ¨¡å‹å“åº”æ—¶é—´
  getModelResponseTime: (modelId: string) => number | undefined; // è·å–æ¨¡å‹å“åº”æ—¶é—´
  getPerformanceIndicator: (modelId: string) => string; // è·å–æ€§èƒ½æŒ‡æ ‡å›¾æ ‡
  getSortedModels: () => AIModelConfig[]; // è·å–æŒ‰å“åº”æ—¶é—´æ’åºçš„æ¨¡å‹åˆ—è¡¨
  getRecommendedModel: () => string; // è·å–æ¨èçš„æ¨¡å‹ï¼ˆæœ€å¿«çš„ï¼‰
  updateAverageResponseTime: (modelId: string, responseTime: number) => void; // æ›´æ–°æ¨¡å‹å¹³å‡å“åº”æ—¶é—´
}

const AIContext = createContext<AIContextType | undefined>(undefined);

interface AIProviderProps {
  children: ReactNode;
}

export function AIProvider({ children }: AIProviderProps) {
  const [region, setRegion] = useState('overseas');
  const [selectedChatModel, setSelectedChatModel] = useState('openai'); // é»˜è®¤ä½¿ç”¨OpenAI GPT-4o
  const [selectedImageModel, setSelectedImageModel] = useState('dall-e');
  const [modelConfigs, setModelConfigs] = useState<ModelConfigs | null>(null);
  const [isLoading, setIsLoading] = useState(true);

  const refreshGeoLocation = async () => {
    setIsLoading(true);
    try {
      // è°ƒç”¨æ¨¡å‹é€‰æ‹© Edge Function
      const { data, error } = await supabase.functions.invoke('geo-ai-model-selection', {
        method: 'GET',
      });

      if (error) {
        throw new Error(`æ¨¡å‹é€‰æ‹©æœåŠ¡é”™è¯¯: ${error.message}`);
      }

      console.log('è·å–åˆ°åœ°ç†å®šä½æ•°æ®:', data);
      const modelData = data.data;
      setRegion(modelData.region);

      // æ ¹æ®åŒºåŸŸé€‰æ‹©æ¨¡å‹
      const recommendedChatModel = modelData.recommendedModels.chat;
      
      // æ›´æ–°æ¨¡å‹é…ç½®
      setModelConfigs(modelData.modelConfigs);

      // å¦‚æœç”¨æˆ·æ²¡æœ‰æ‰‹åŠ¨é€‰æ‹©æ¨¡å‹ï¼Œåˆ™ä½¿ç”¨å»ºè®®æ¨¡å‹
      const savedChatModel = localStorage.getItem('leoai-chat-model');
      if (!savedChatModel) {
        setSelectedChatModel(recommendedChatModel);
      }

      // ä¿å­˜å›¾åƒæ¨¡å‹é€‰æ‹©
      const savedImageModel = localStorage.getItem('leoai-image-model');
      if (!savedImageModel) {
        setSelectedImageModel(modelData.recommendedModels.image);
      }

      // ä¿å­˜åŒºåŸŸä¿¡æ¯åˆ°æœ¬åœ°å­˜å‚¨
      localStorage.setItem('leoai-region', modelData.region);
      localStorage.setItem('leoai-recommended-model', recommendedChatModel);
    } catch (error) {
      console.error('è·å–åŸºäºåœ°ç†ä½ç½®çš„æ¨¡å‹é…ç½®å¤±è´¥:', error);
      // ä½¿ç”¨æœ¬åœ°å…œåº•é…ç½®ï¼Œæä¾› openai/qwen/deepseek ä¸‰æ¨¡å‹
      setRegion('overseas');
      const defaultModel = 'openai'; // GPT-4o ä½œä¸ºé»˜è®¤
      setSelectedChatModel(defaultModel);
      setSelectedImageModel('dall-e');
      setModelConfigs({
        chat: {
          available: [
            { id: 'openai', name: 'OpenAI GPT-4o', enabled: true, recommended: true },
            { id: 'qwen', name: 'Qwen Turbo', enabled: true, recommended: false },
            { id: 'deepseek', name: 'DeepSeek', enabled: true, recommended: false },
          ]
        },
        image: {
          available: [
            { id: 'dall-e', name: 'DALLÂ·E', enabled: true, recommended: true }
          ]
        }
      });
    } finally {
      setIsLoading(false);
    }
  };

  // è®¾ç½®åˆå§‹åŒ–çŠ¶æ€
  useEffect(() => {
    // è®¾ç½®åˆå§‹åŒ–çŠ¶æ€
    const initialize = async () => {
      try {
        setIsLoading(true);
        // åŠ è½½ä¿å­˜çš„åå¥½è®¾ç½®
        const savedChatModel = localStorage.getItem('leoai-chat-model');
        const savedImageModel = localStorage.getItem('leoai-image-model');
        const savedRegion = localStorage.getItem('leoai-region');
        const savedRecommendedModel = localStorage.getItem('leoai-recommended-model');

        // ä¼˜å…ˆä½¿ç”¨ç”¨æˆ·æ‰‹åŠ¨é€‰æ‹©çš„æ¨¡å‹
        if (savedChatModel) {
          setSelectedChatModel(savedChatModel);
        } else if (savedRecommendedModel) {
          // å…¶æ¬¡ä½¿ç”¨ä¹‹å‰æ£€æµ‹åˆ°çš„æ¨èæ¨¡å‹
          setSelectedChatModel(savedRecommendedModel);
        } else {
          // æœ€åä½¿ç”¨é»˜è®¤æ¨¡å‹
          const currentLang = localStorage.getItem('i18nextLng') || 'en';
          const defaultModel = getRecommendedModelByUserPreference(currentLang);
          setSelectedChatModel(defaultModel);
          // è‹¥è¿œç«¯æœªè¿”å›ï¼Œåˆå§‹åŒ–æœ¬åœ°å…œåº•æ¨¡å‹åˆ—è¡¨
          if (!modelConfigs) {
            setModelConfigs({
              chat: {
                available: [
                  { id: 'openai', name: 'OpenAI GPT-4o', enabled: true, recommended: true },
                  { id: 'qwen', name: 'Qwen Turbo', enabled: true, recommended: false },
                  { id: 'deepseek', name: 'DeepSeek', enabled: true, recommended: false },
                ]
              },
              image: {
                available: [
                  { id: 'dall-e', name: 'DALLÂ·E', enabled: true, recommended: true }
                ]
              }
            });
          }
        }
        
        if (savedImageModel) {
          setSelectedImageModel(savedImageModel);
        }

        if (savedRegion) {
          setRegion(savedRegion);
        }

        // è·å–åŸºäºåœ°ç†ä½ç½®çš„é…ç½®
        await refreshGeoLocation();
        
      } catch (error) {
        console.error('åˆå§‹åŒ–AIä¸Šä¸‹æ–‡å¤±è´¥:', error);
      } finally {
        setIsLoading(false);
      }
    };

    initialize();
  }, []);

  const handleSetSelectedChatModel = (model: string) => {
    console.log(`åˆ‡æ¢æ¨¡å‹ä¸º: ${model}`);
    setSelectedChatModel(model);
    localStorage.setItem('leoai-chat-model', model);
    // è§¦å‘è‡ªå®šä¹‰äº‹ä»¶ï¼Œé€šçŸ¥UIæ›´æ–°
    window.dispatchEvent(new CustomEvent('model-changed', { detail: { model } }));
  };

  const handleSetSelectedImageModel = (model: string) => {
    setSelectedImageModel(model);
    localStorage.setItem('leoai-image-model', model);
  };

  // æ›´æ–°æ¨¡å‹å“åº”æ—¶é—´ï¼ˆå…¼å®¹æ—§ç‰ˆæœ¬APIï¼Œå®é™…è°ƒç”¨updateAverageResponseTimeï¼‰
  const updateModelResponseTime = (modelId: string, responseTime: number) => {
    updateAverageResponseTime(modelId, responseTime);
  };

  // è·å–æ¨¡å‹å“åº”æ—¶é—´
  const getModelResponseTime = (modelId: string): number | undefined => {
    if (!modelConfigs) return undefined;
    
    const model = modelConfigs.chat.available.find(m => m.id === modelId);
    // å¦‚æœå“åº”æ—¶é—´å­˜åœ¨ï¼Œä»æ¯«ç§’è½¬æ¢ä¸ºç§’
    if (model?.avgResponseTime) {
      return Math.round(model.avgResponseTime / 1000);
    }
    return undefined;
  };

  // è·å–æ€§èƒ½æŒ‡æ ‡å›¾æ ‡
  const getPerformanceIndicator = (modelId: string): string => {
    const responseTime = getModelResponseTime(modelId);
    if (responseTime === undefined) return 'âš™ï¸'; // é»˜è®¤å›¾æ ‡
    
    if (responseTime <= 10) return 'âš¡'; // å¿«é€Ÿ
    if (responseTime <= 20) return 'ğŸœ€'; // ä¸­ç­‰
    return 'ğŸš€'; // è¾ƒæ…¢
  };
  
  // è·å–æŒ‰å“åº”æ—¶é—´æ’åºçš„æ¨¡å‹åˆ—è¡¨
  const getSortedModels = (): AIModelConfig[] => {
    if (!modelConfigs) return [];
    
    // å¤åˆ¶æ¨¡å‹åˆ—è¡¨ï¼Œé¿å…ä¿®æ”¹åŸå§‹æ•°æ®
    const models = [...modelConfigs.chat.available];
    
    // æŒ‰å“åº”æ—¶é—´æ’åºï¼ˆä»å¿«åˆ°æ…¢ï¼‰
    return models.sort((a, b) => {
      const timeA = a.avgResponseTime || Number.MAX_SAFE_INTEGER;
      const timeB = b.avgResponseTime || Number.MAX_SAFE_INTEGER;
      return timeA - timeB;
    });
  };
  
  // è·å–åŸºäºç”¨æˆ·è¯­è¨€å’ŒåŒºåŸŸçš„æ¨èæ¨¡å‹
  const getRecommendedModelByUserPreference = (userLanguage: string): string => {
    // è·å–ç”¨æˆ·å½“å‰è¯­è¨€ (i18n è¯­è¨€è®¾ç½®)
    const isChineseUser = userLanguage.toLowerCase().startsWith('zh');
    
    // æ£€æŸ¥æ˜¯å¦å¯èƒ½æ˜¯ä¸­å›½ç”¨æˆ· (åŸºäºæ—¶åŒºå’Œè¯­è¨€ç­‰å› ç´ )
    const timezone = new Date().getTimezoneOffset() / -60;
    const possibleChineseUser = isChineseUser || timezone === 8; // ä¸­å›½æ ‡å‡†æ—¶åŒºæ˜¯UTC+8
    
    // æ ¹æ®ä¸åŒè¯­è¨€è¿”å›ä¸åŒçš„æ¨¡å‹
    // ç®€ä½“åŠç¹ä½“ä¸­æ–‡ç”¨æˆ·ï¼ˆä¸­å›½IPï¼‰é»˜è®¤ä½¿ç”¨ Qwenï¼ˆé˜¿é‡Œé€šä¹‰åƒé—®ï¼‰
    // è‹±æ–‡å’Œå…¶ä»–è¯­è¨€ç”¨æˆ·ï¼ˆæµ·å¤–IPï¼‰é»˜è®¤ä½¿ç”¨ OpenAI GPT-4o
    if (possibleChineseUser && isChineseUser) {
      return 'qwen'; // ä¸­å›½ç”¨æˆ·ä½¿ç”¨Qwenï¼ˆé˜¿é‡Œé€šä¹‰åƒé—®ï¼‰
    } else {
      return 'openai'; // æ‰€æœ‰å…¶ä»–ç”¨æˆ·ä¼˜å…ˆä½¿ç”¨OpenAI GPT-4o
    }
  };
  
  // è·å–æ¨èçš„æ¨¡å‹ï¼ˆæ ¹æ®ç”¨æˆ·è¯­è¨€æˆ–è€…é€‰æ‹©å“åº”æœ€å¿«çš„ï¼‰
  const getRecommendedModel = (): string => {
    // ä¼˜å…ˆçº§:
    // 1. æ‰‹åŠ¨è®¾ç½®çš„æ¨¡å‹
    // 2. æ ¹æ®è¯­è¨€è‡ªåŠ¨é€‰æ‹©çš„æ¨¡å‹
    // 3. å“åº”æœ€å¿«çš„æ¨¡å‹
    
    // æ£€æŸ¥æ˜¯å¦æœ‰ç”¨æˆ·è‡ªå®šä¹‰è®¾ç½®
    const userDefinedModel = localStorage.getItem('leoai-chat-model-preference');
    if (userDefinedModel) {
      return userDefinedModel;
    }
    
    // è¯­è¨€ä¼˜åŒ–é€‰æ‹©
    // ä» localStorage è·å–å½“å‰è¯­è¨€
    const currentLang = localStorage.getItem('i18nextLng') || 'en';
    const languageBasedModel = getRecommendedModelByUserPreference(currentLang);
    
    // è·å–å“åº”æœ€å¿«çš„æ¨¡å‹ï¼ˆåœ¨æ²¡æœ‰å…¶ä»–åå¥½è®¾ç½®çš„æƒ…å†µä¸‹ä½œä¸ºå¤‡ç”¨ï¼‰
    const sortedModels = getSortedModels();
    const fastestModel = sortedModels.find(m => m.enabled);
    const fastestModelId = fastestModel?.id || 'deepseek'; // é»˜è®¤å°±æ˜¯ deepseek
    
    // è¿”å›è¯­è¨€ä¼˜åŒ–é€‰æ‹©æˆ–æœ€å¿«æ¨¡å‹
    return languageBasedModel || fastestModelId;
  };
  
  // æ›´æ–°æ¨¡å‹å¹³å‡å“åº”æ—¶é—´ï¼ˆåŸºäºå¤šæ¬¡æµ‹é‡çš„å®æ—¶å¹³å‡ï¼‰
  const updateAverageResponseTime = (modelId: string, responseTime: number) => {
    if (!modelConfigs) return;

    setModelConfigs((prevConfigs) => {
      if (!prevConfigs) return prevConfigs;

      // æ·±å¤åˆ¶å½“å‰é…ç½®
      const newConfigs = {
        ...prevConfigs,
        chat: {
          ...prevConfigs.chat,
          available: [...prevConfigs.chat.available]
        }
      };

      // æŸ¥æ‰¾å¹¶æ›´æ–°ç›®æ ‡æ¨¡å‹
      const modelIndex = newConfigs.chat.available.findIndex(model => model.id === modelId);
      if (modelIndex !== -1) {
        const model = newConfigs.chat.available[modelIndex];
        const currentCount = model.responseCount || 0;
        const currentAvgTime = model.avgResponseTime || 0;
        
        // è®¡ç®—æ–°çš„å¹³å‡å“åº”æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
        const newCount = currentCount + 1;
        // å“åº”æ—¶é—´ä¼ å…¥çš„æ˜¯ç§’ï¼Œéœ€è¦è½¬æ¢ä¸ºæ¯«ç§’è¿›è¡Œå­˜å‚¨
        const responseTimeMs = responseTime * 1000;
        const newAvgTime = Math.round((currentAvgTime * currentCount + responseTimeMs) / newCount);
        
        newConfigs.chat.available[modelIndex] = {
          ...model,
          avgResponseTime: newAvgTime,
          responseCount: newCount
        };

        // è‡ªåŠ¨è®¾ç½®æœ€å¿«çš„æ¨¡å‹ä¸ºé»˜è®¤æ¨è
        const sortedModels = [...newConfigs.chat.available].sort((a, b) => {
          const timeA = a.avgResponseTime || Number.MAX_SAFE_INTEGER;
          const timeB = b.avgResponseTime || Number.MAX_SAFE_INTEGER;
          return timeA - timeB;
        });
        
        // æ›´æ–°æ¨èçŠ¶æ€
        if (sortedModels.length > 0) {
          const fastestModelId = sortedModels[0].id;
          newConfigs.chat.available = newConfigs.chat.available.map(m => ({
            ...m,
            recommended: m.id === fastestModelId
          }));
        }

        // ä¿å­˜åˆ°æœ¬åœ°å­˜å‚¨
        localStorage.setItem(`leoai-model-${modelId}-avgTime`, newAvgTime.toString());
        localStorage.setItem(`leoai-model-${modelId}-count`, newCount.toString());
        
        // å¦‚æœè¿™ä¸ªæ¨¡å‹æ˜¯æœ€å¿«çš„ï¼Œè‡ªåŠ¨è®¾ç½®ä¸ºé»˜è®¤
        const fastestModel = sortedModels[0];
        if (fastestModel && fastestModel.id !== selectedChatModel) {
          // ä¸ç«‹å³åˆ‡æ¢ï¼Œåªåœ¨æœ¬åœ°å­˜å‚¨ä¸­æ ‡è®°
          localStorage.setItem('leoai-fastest-model', fastestModel.id);
        }
      }

      return newConfigs;
    });
  };

  useEffect(() => {
    // ä»æœ¬åœ°å­˜å‚¨åŠ è½½æ¨¡å‹å“åº”æ—¶é—´ç»Ÿè®¡
    const loadModelStats = () => {
      if (modelConfigs) {
        const newConfigs = {
          ...modelConfigs,
          chat: {
            ...modelConfigs.chat,
            available: [...modelConfigs.chat.available]
          }
        };

        // ä»æœ¬åœ°å­˜å‚¨ä¸­åŠ è½½å¹¶æ›´æ–°æ¯ä¸ªæ¨¡å‹çš„æ•°æ®
        newConfigs.chat.available.forEach((model, index) => {
          const savedAvgTime = localStorage.getItem(`leoai-model-${model.id}-avgTime`);
          const savedCount = localStorage.getItem(`leoai-model-${model.id}-count`);
          
          if (savedAvgTime && savedCount) {
            newConfigs.chat.available[index] = {
              ...model,
              avgResponseTime: parseInt(savedAvgTime),
              responseCount: parseInt(savedCount)
            };
          }
        });

        setModelConfigs(newConfigs);
      }
    };

    loadModelStats();
  }, [modelConfigs?.chat.available.length]); // ä»…åœ¨æ¨¡å‹åˆ—è¡¨åŠ è½½æ—¶æ‰§è¡Œ

  const value = {
    region,
    selectedChatModel,
    selectedImageModel,
    modelConfigs,
    isLoading,
    setSelectedChatModel: handleSetSelectedChatModel,
    setSelectedImageModel: handleSetSelectedImageModel,
    refreshGeoLocation,
    updateModelResponseTime,
    getModelResponseTime,
    getPerformanceIndicator,
    getSortedModels,
    getRecommendedModel,
    updateAverageResponseTime
  };

  return (
    <AIContext.Provider value={value}>
      {children}
    </AIContext.Provider>
  );
}

export function useAI() {
  const context = useContext(AIContext);
  if (context === undefined) {
    throw new Error('useAI must be used within an AIProvider');
  }
  return context;
}